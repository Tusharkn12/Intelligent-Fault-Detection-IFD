# -*- coding: utf-8 -*-
"""IFD

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OpxkN9sCoHMC35pcySG0xZT2UYVd4kBt
"""
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
import pandas as pd
from xgboost import XGBClassifier as XGB
from  umap import UMAP
import seaborn as sns
from sklearn.ensemble import IsolationForest
from sklearn.svm import OneClassSVM as ocsvm
from tensorflow.keras.layers import Dense, Flatten, Conv2D, Conv2DTranspose, BatchNormalization, Dropout, MaxPooling2D, Multiply, Input, LSTM, GRU, ZeroPadding2D, Reshape
from tensorflow.keras.models import Model
from tensorflow.keras.utils import plot_model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.applications import MobileNetV3Small
from tensorflow.keras.activations import relu
import keras
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_score, mean_squared_error
from sklearn.model_selection import train_test_split
from sklearn.cluster import kmeans_plusplus

@keras.saving.register_keras_serializable()
class DataGenerator(tf.keras.layers.Layer):
  """Transform  signal into 2D image
  img_shape :  Shape of transformed image
  n_f : No of features
  """

  def __init__(self, img_shape, n_f):
    super(DataGenerator, self).__init__()
    self.img_shape = img_shape
    self.n_f = n_f

  @tf.function
  def call(self, inputs):
    batch_size = tf.shape(inputs)[0]
    fft_sig = tf.signal.fft(tf.cast(inputs, tf.complex64))
    fft_real = tf.math.real(fft_sig)
    fft_imag = tf.math.imag(fft_sig)
    fft_img_real = tf.reshape(fft_real,  shape = (batch_size, self.img_shape[0], self.img_shape[1], self.n_f))
    fft_img_imag = tf.reshape(fft_imag, shape = (batch_size,self.img_shape[0], self.img_shape[1], self.n_f))
    inputs_img = tf.reshape(inputs, shape = (batch_size,self.img_shape[0], self.img_shape[1], self.n_f))
    return tf.concat([fft_img_real, fft_img_imag, inputs_img], axis  = -1)

  def get_config(self):
    config = super(DataGenerator, self).get_config()
    config.update({'img_shape':self.img_shape, 'n_f':self.n_f})
    return config

  def compute_output_shape(self, input_shape):
    return (None, self.img_shape[0], self.img_shape[1], 3*self.n_f)
  @classmethod
  def from_config(cls, config):
    return cls(**config)

@keras.saving.register_keras_serializable()
class DataReverser(tf.keras.layers.Layer):
  """Transform 2D image into signal
  T_x : NO of timesteps
  n_f : NO of feaTures
  batch_size : No of examples in single batch"""

  def __init__(self, T_x, n_f, batch_size):
    super(DataReverser, self).__init__()
    self.T_x = T_x
    self.n_f = n_f

  @tf.function
  def call(self, inputs):
    splitted_image = tf.split(inputs,num_or_size_splits = 3 ,axis = -1)
    inputs_img = splitted_image[2]
    inputs_array = tf.reshape(inputs_img, shape = (-1, self.T_x, self.n_f))

    return inputs_array

  def get_config(self):
    config = super(DataReverser, self).get_config()
    config.update({"T_x":self.T_x, "n_f":self.n_f})
    return config

  @classmethod
  def from_config(cls, config):
    return cls(**config)

@keras.saving.register_keras_serializable()
class Conv_layer(tf.keras.layers.Layer):
  """Conv_layer for feature extaraction from 2D image of signal
  conv_model : Convolutional model(Custom)
  autoencoder_status = True if conv_model is autoencoder
  """

  def __init__(self, conv_model, autoencoder_status):
    super(Conv_layer, self).__init__()
    self.conv_model = conv_model
    self.conv_model_config = conv_model.to_json()
    self.conv_input = conv_model.input
    #Checking for AutoEncoder status because autoencoder require different conditioning of pre_xgb_model
    if autoencoder_status:
      try:
        self.conv_output = conv_model.get_layer("Middle").output
      except:
        raise MissingLayerName(f""" The layer name "Middle" is not found in the conv_model
                                   ///Ensure that provided conv model has a layer named Middle
                                   'Middle Layer is bottleneck layer
                                   If you are Making ConvLSTM then "Middle" should be the name of extra layer after LSTM output"
                                    """)  from None
    else:
      try:
        self.conv_output = conv_model.get_layer("Flatten").output
      except :
        raise MissingLayerName(f""" The layer name "Flatten" is not found in the conv_model
                                   ///The provided model must include a 'Flatten' layer if it is not an autoencoder.
                                   'Flatten Layer Flattens the input. Does not affect the batch size.' """)  from None
    #Creating a model
    self.pre_xgb_model = Model(inputs = [self.conv_input], outputs = [self.conv_output])

  @tf.function
  def call(self, inputs):
    return self.conv_model(inputs)


  def get_config(self):
    config = super(Conv_layer, self).get_config()
    config.update({'conv_model_config':self.conv_model_config})
    return config

  def compute_output_shape(self, input_shape):
    return self.conv_model.output_shape

  @classmethod
  def from_config(cls, config):
    return cls(**config)

@keras.saving.register_keras_serializable()
class ConvXGB_layer(tf.keras.layers.Layer):
  """Layer for joining conv_model with XGB model
  XGB_model : Custom XGB model
  pre_xgb_model : Model containing input layer, datagenerator layer with modified version of a convolutional neural network (CNN),
  designed to extract features from an intermediate or flatten layer of the
  original model depending on the autoencoder_status"""

  def __init__(self, XGB_model, pre_xgb_model):
    super(ConvXGB_layer, self).__init__()
    self.XGB_model = XGB_model
    self.pre_xgb_model = pre_xgb_model


  def _train_forest(self, Conv_stored, y_train):
    self.XGB_model.fit(Conv_stored, y_train)


  def get_config(self):
    config = super().get_config()
    config.update({'pre_xgb_model_config': self.pre_xgb_model.to_json(), 'XGB_param':self.XGB_model.get_params()})
    return config

  @classmethod
  def from_config(cls, config):
    return cls(**config)

@keras.saving.register_keras_serializable()
class ConvISO_layer(tf.keras.layers.Layer):
  """Layer for joining conv_model with Isolation Forest model
  ISO_model : Custom Isolation model
  pre_iso_model : Model containing input layer, datagenerator layer with modified version of a convolutional neural network (CNN),
  designed to extract features from an intermediate or flatten layer of the
  original model depending on the autoencoder_status"""

  def __init__(self, ISO_model, pre_iso_model):
    super(ConvISO_layer, self).__init__()
    self.ISO_model = ISO_model
    self.pre_iso_model = pre_iso_model

  def _train_forest(self, conv_stored):
    return self.ISO_model.fit(conv_stored)

  def get_config(self):
    config = super().get_config()
    config.update({"ISO_model_config":self.pre_iso_model.get_params(), "pre_iso_model_config":self.pre_iso_model.to_json()})
    return config

  @classmethod
  def from_config(cls, config):
    return cls(**config)

@keras.saving.register_keras_serializable()
class ConvSVM_layer(tf.keras.layers.Layer):
  """Layer for joining conv_model with SVM model
  SVM_model : Custom SVM model
  pre_svm_model : Model containing input layer, datagenerator layer with modified version of a convolutional neural network (CNN),
  designed to extract features from an intermediate or flatten layer of the
  original model depending on the autoencoder_status"""

  def __init__(self, SVM_model, pre_svm_model):
    super(ConvSVM_layer, self).__init__()
    self.SVM_model = SVM_model
    self.pre_svm_model = pre_svm_model

  def _train_SVM(self, conv_stored):
    return self.SVM_model.fit(conv_stored)

  def get_config(self):
    config = super().get_config()
    config.update({"pre_SVM_config":2, "pre_svm_model_config":self.pre_svm_model.to_json()})
    return config

  @classmethod
  def from_config(cls, config):
    return cls(**config)


class InvalidDimensions(Exception):
  "Exception for Invalid dimensioning of Model"
  pass

class NotImplemented(Exception):
  "Exception raised when requierd method or layer intialization is missing"
  pass

class MissingLayerName(Exception):
  "Exception for handling for missing parameters in Conv_layer."
  pass

class IFD:
  """Attributes:
  transformed_img_shape:
  n_f:
  T_x:
  num_pred:
  batch_size:
  replace_part:"""

  def __init__(self, transformed_img_shape, n_f, T_x,  num_pred, batch_size = 32, replace_part = True) -> None:
    self.transformed_img_shape = transformed_img_shape
    self.n_f = n_f
    self.T_x = T_x
    self.num_pred= num_pred
    self.batch_size = batch_size
    self.replace_part = replace_part

  def set_conv_layer(self, conv_model, auto_encoder = False) -> None:
    """Creates conv_layer
    conv_model : Custom convolutional model
    auto_encoder = True if conv_model has an autoencoder architecture"""
    self.conv_layer = Conv_layer(conv_model, auto_encoder)
    self.conv_model_input = conv_model.input_shape
    self.conv_model_output = conv_model.output_shape
    self.auto_encoder_status = auto_encoder
    print("conv_layer is created")

  def set_Data_generator(self) ->None:
    """Creates DataGenerator Layer"""
    self.data_generator = DataGenerator(self.transformed_img_shape, self.n_f)
    self.data_generator_output = self.data_generator.compute_output_shape((self.batch_size, self.T_x, self.n_f))
    print("DataGenerator is created")
######################################################################################################################################################################
  def conditions_check(self)  -> bool:
    "Method to check conditions for proper alignment of different layers together"
    N, M = self.transformed_img_shape
    if N*M != self.T_x:
      raise InvalidDimensions(f"Size of Image should match the time step length of signal {N*M} != {self.T_x}")
    if not hasattr(self, "conv_model_input"):
      raise NotImplemented(f"""First initialize the conv layer using {type(self).__name__}.set_conv_layer() method.
       IFD's object has no attribute with name conv_model_input""")

    if not hasattr(self, "data_generator_output"):
      raise NotImplemented(f"First initialize the Data Generator Layer using {type(self).__name__}.set_Data_Generator() method")

    if not hasattr(self, "conv_model_output"):
      raise NotImplemented(f"First initialize the conv layer using {type(self).__name__}.set_conv_layer() method")

    if self.conv_model_input != self.data_generator_output:
      raise InvalidDimensions(f"Input of Conv model doesn't match the output of DataGenerator Layer//{self.conv_model_input}!= {self.data_generator_output}")

    if self.auto_encoder_status == False and self.conv_model_output[-1] != self.num_pred:
      if len(self.conv_model_output)!= 2:
        raise NotImplemented(f"""//Please do auto_encoder == True if you are using auto encoder architecture for unsupervised learning""")
      else:
        raise InvalidDimensions(f"conv_model_output should be equal to the num of predictions in this case {self.num_pred}")

    if self.auto_encoder_status == True and self.conv_model_output != self.conv_model_input:
      raise InvalidDimensions(f"Output shape  of conv model should be equal to input shape for autoencoder// In these Case {self.conv_model_output} != {self.conv_model_input}")

    ###Checking conditions for AutoEncoder
    ##TO DO
    if self.auto_encoder_status == True:
      pass
    return True
##########################################################################################################################################################################
  def create_and_train_ConvXGB(self, created_model, XGB_model, X_train, y_train) :

    """Use this method after trainig to remove the fnn layer and fit XGB model
    created_model : Main model created by using create_model method
    XGB_model : Custom XGB model
    X_train : Training dataset containing input featuers for model to learn
    y_train : Training dataset containing labels  for model to learn"""

    if self.replace_part == True and created_model.weights:
      pre_xgb_generator = DataGenerator(self.transformed_img_shape, self.n_f)
      #Creating ConvXGB model
      inp = Input(shape = (self.T_x, self.n_f), name = "Inputs")
      generated_data = pre_xgb_generator(inp)

      if self.auto_encoder_status == True:
        pre_xgb_model = created_model.get_layer(index = -2).pre_xgb_model
        conv_output = pre_xgb_model(generated_data)
        conv_output_flatten = Flatten()(conv_output[0]) #Flattening after middle layer in autoencoder for fitting xgb model
        side_xgb_model = Model(inputs = [inp], outputs = [conv_output_flatten])
        side_xgb_model.summary()
        Conv_stored = side_xgb_model(X_train)
      else:
        pre_xgb_model = created_model.get_layer(index = -1).pre_xgb_model
        conv_output = pre_xgb_model(generated_data)
        side_xgb_model = Model(inputs = [inp], outputs = [conv_output])
        side_xgb_model.summary()
        Conv_stored = side_xgb_model(X_train)[0]

      ConvXGB = ConvXGB_layer(XGB_model, side_xgb_model)
      Conv_stored = tf.numpy_function(func = lambda x : np.array(x), inp = [Conv_stored], Tout = tf.float32)
      ConvXGB._train_forest(Conv_stored, y_train)


    else:
      print("Model is not trained yet//Trained Model is important for creating ConvXGB")

    return ConvXGB

  def create_and_train_ConvISO(self, created_model, ISO_model, X_train):
    """Use this method after trainig to remove the fnn layer and fit XGB model
    created_model : Main model created by using create_model method
    ISO_model : Custom Isolation model
    X_train : Training dataset containing input featuers for model to learn """

    if self.replace_part== True and created_model.weights:
      pre_iso_generator = DataGenerator(self.transformed_img_shape, self.n_f)
      #Creating ConvISO model
      inp = Input(shape = (self.T_x, self.n_f), name = "Inputs")
      generated_data = pre_iso_generator(inp)

      if self.auto_encoder_status == True:
        pre_iso_model = created_model.get_layer(index = -2).pre_xgb_model
        conv_output = pre_iso_model(generated_data)
        conv_output_flatten = Flatten()(conv_output[0])
        side_iso_model = Model(inputs = [inp], outputs = [conv_output_flatten])
        Conv_stored = side_iso_model(X_train)
      else:
        pre_iso_model = created_model.get_layer(index = -1).pre_xgb_model
        conv_output = pre_iso_model(generated_data)
        side_iso_model = Model(inputs = [inp], outputs = [conv_output])
        side_iso_model.summary()
        Conv_stored = side_iso_model(X_train)[0]

      ConvISO = ConvISO_layer(ISO_model, side_iso_model)
      Conv_stored = tf.numpy_function(func = lambda x : np.array(x), inp = [Conv_stored], Tout = tf.float32)
      ConvISO._train_forest(Conv_stored)
    else:
      print("Model is not trained yet//Trained Model is important for creating ConvXGB")

    return ConvISO


  def create_and_train_ConvSVM(self, created_model, SVM_model, X_train):
    """Use this method after trainig to remove the fnn layer and fit XGB model
    created_model : Main model created by using create_model method
    SVM_model : Custom SVM model
    X_train : Training dataset containing input featuers for model to learn """

    if self.replace_part  == True and created_model.weights:
      pre_svm_generator = DataGenerator(self.transformed_img_shape, self.n_f)
      #Creating ConvSVM model
      inp = Input(shape = (self.T_x, self.n_f), name = "Inputs")
      generated_data = pre_svm_generator(inp)

      if self.auto_encoder_status == True:
        pre_svm_model = created_model.get_layer(index = -2).pre_xgb_model
        conv_output = pre_svm_model(generated_data)
        conv_output_flatten = Flatten()(conv_output[0])
        side_svm_model = Model(inputs = [inp], outputs = [conv_output_flatten])
        Conv_stored = side_svm_model(X_train)
      else:
        pre_svm_model = created_model.get_layer(index = -1).pre_xgb_model
        conv_output = pre_svm_model(generated_data)
        side_svm_model = Model(inputs = [inp], outputs = [conv_output])
        side_svm_model.summary()
        Conv_stored = side_svm_model(X_train)[0]

      ConvSVM = ConvSVM_layer(SVM_model, side_svm_model)
      Conv_stored = tf.numpy_function(func = lambda x : np.array(x), inp = [Conv_stored], Tout = tf.float32)
      ConvSVM._train_SVM(Conv_stored)
    else:
      print("Model is not trained yet//Trained Model is important for creating ConvXGB")

    return ConvSVM

  def create_model(self):
    #Input layer
    inp = Input(shape = (self.T_x, self.n_f), name = "Inputs")
    #Checking all conditions
    if self.conditions_check():
      print("DataGenerator and Conv_layer is merged")
    #Data generator
    generated_data = self.data_generator(inp)
    conv_output = self.conv_layer(generated_data)
    if self.auto_encoder_status == True:
      rev_conv_output = DataReverser(self.T_x, self.n_f, self.batch_size)(conv_output)
      model = Model(inputs = [inp], outputs = [rev_conv_output])
    else:
      model = Model(inputs = [inp], outputs = [conv_output])

    return model

